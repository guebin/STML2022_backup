{
  
    
        "post0": {
            "title": "(2주차) 9월14일",
            "content": "imports . from fastai.collab import * ## 추천시스템 from fastai.text.all import * ## 텍스트분석 from fastai.vision.all import * ## GAN (이미지분석) from fastai.vision.gan import * ## GAN (이미지생성) . import pandas as pd . fastai&#47484; &#51060;&#50857;&#54620; &#48516;&#49437; steps . - 비교 . 이미지분석(CNN) 추천시스템 텍스트분석 GAN . 1단계 | ImageDataLoaders | CollabDataLoaders | TextDataLoaders | DataBlock -&gt; dls | . 2단계 | cnn_learner() | collab_learner() | language_model_learner() | GANLearner.wgan() | . 3단계 | lrnr.fine_tune(1) | lrnr.fit() | lrnr.fit() | lrnr.fit() | . 4단계 | lrnr.predict(), lrnr.model(X) | lrnr.model(X) | lrnr.predict() | | . &#52628;&#52380;&#49884;&#49828;&#53596; . 1&#45800;&#44228; . df_view = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_view.csv&#39;) df_view . 커피1 커피2 커피3 커피4 커피5 커피6 커피7 커피8 커피9 커피10 홍차1 홍차2 홍차3 홍차4 홍차5 홍차6 홍차7 홍차8 홍차9 홍차10 . 0 4.149209 | NaN | NaN | 4.078139 | 4.033415 | 4.071871 | NaN | NaN | NaN | NaN | 1.142659 | 1.109452 | NaN | 0.603118 | 1.084308 | NaN | 0.906524 | NaN | NaN | 0.903826 | . 1 4.031811 | NaN | NaN | 3.822704 | NaN | NaN | NaN | 4.071410 | 3.996206 | NaN | NaN | 0.839565 | 1.011315 | NaN | 1.120552 | 0.911340 | NaN | 0.860954 | 0.871482 | NaN | . 2 4.082178 | 4.196436 | NaN | 3.956876 | NaN | NaN | NaN | 4.450931 | 3.972090 | NaN | NaN | NaN | NaN | 0.983838 | NaN | 0.918576 | 1.206796 | 0.913116 | NaN | 0.956194 | . 3 NaN | 4.000621 | 3.895570 | NaN | 3.838781 | 3.967183 | NaN | NaN | NaN | 4.105741 | 1.147554 | NaN | 1.346860 | NaN | 0.614099 | 1.297301 | NaN | NaN | NaN | 1.147545 | . 4 NaN | NaN | NaN | NaN | 3.888208 | NaN | 3.970330 | 3.979490 | NaN | 4.010982 | NaN | 0.920995 | 1.081111 | 0.999345 | NaN | 1.195183 | NaN | 0.818332 | 1.236331 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 95 0.511905 | 1.066144 | NaN | 1.315430 | NaN | 1.285778 | NaN | 0.678400 | 1.023020 | 0.886803 | NaN | 4.055996 | NaN | NaN | 4.156489 | 4.127622 | NaN | NaN | NaN | NaN | . 96 NaN | 1.035022 | NaN | 1.085834 | NaN | 0.812558 | NaN | 1.074543 | NaN | 0.852806 | 3.894772 | NaN | 4.071385 | 3.935935 | NaN | NaN | 3.989815 | NaN | NaN | 4.267142 | . 97 NaN | 1.115511 | NaN | 1.101395 | 0.878614 | NaN | NaN | NaN | 1.329319 | NaN | 4.125190 | NaN | 4.354638 | 3.811209 | 4.144648 | NaN | NaN | 4.116915 | 3.887823 | NaN | . 98 NaN | 0.850794 | NaN | NaN | 0.927884 | 0.669895 | NaN | NaN | 0.665429 | 1.387329 | NaN | NaN | 4.329404 | 4.111706 | 3.960197 | NaN | NaN | NaN | 3.725288 | 4.122072 | . 99 NaN | NaN | 1.413968 | 0.838720 | NaN | NaN | 1.094826 | 0.987888 | NaN | 1.177387 | 3.957383 | 4.136731 | NaN | 4.026915 | NaN | NaN | 4.164773 | 4.104276 | NaN | NaN | . 100 rows × 20 columns . row0 - row49 에 해당하는 유저는 커피를 선호 | row50 - row99 에 해당하는 유저는 홍차를 선호 | . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv&#39;) df . user item rating item_name . 0 1 | 15 | 1.084308 | 홍차5 | . 1 1 | 1 | 4.149209 | 커피1 | . 2 1 | 11 | 1.142659 | 홍차1 | . 3 1 | 5 | 4.033415 | 커피5 | . 4 1 | 4 | 4.078139 | 커피4 | . ... ... | ... | ... | ... | . 995 100 | 18 | 4.104276 | 홍차8 | . 996 100 | 17 | 4.164773 | 홍차7 | . 997 100 | 14 | 4.026915 | 홍차4 | . 998 100 | 4 | 0.838720 | 커피4 | . 999 100 | 7 | 1.094826 | 커피7 | . 1000 rows × 4 columns . 컴퓨터는 이러한 형태를 더 분석하기 좋아한다. | . df.item.unique(),df.user.unique() # 유저는 1~100 으로 아이템은 1~20으로 번호가 매겨져 있음 . (array([15, 1, 11, 5, 4, 14, 6, 20, 12, 17, 8, 9, 13, 19, 18, 16, 2, 3, 10, 7]), array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100])) . dls=CollabDataLoaders.from_df(df) . dls.show_batch() . user item rating . 0 2 | 1 | 4.031811 | . 1 40 | 19 | 1.015886 | . 2 39 | 20 | 0.853394 | . 3 58 | 8 | 0.854745 | . 4 38 | 6 | 4.055263 | . 5 45 | 17 | 0.608018 | . 6 59 | 14 | 3.986921 | . 7 6 | 12 | 0.833454 | . 8 98 | 13 | 4.354638 | . 9 74 | 12 | 4.199568 | . X,y= dls.one_batch() . X[0],y[0] . (tensor([64, 15]), tensor([4.1146])) . 64번 유저가 15번 아이템을 먹었을때 평점을 4.1146 주었음 | . 2&#45800;&#44228; . lrnr = collab_learner(dls,y_range=(0,5)) # y_range는 평점의 범위 . 3&#45800;&#44228; . lrnr.fit(10) # 총 30번 정도 해야 적합이 잘된다. . epoch train_loss valid_loss time . 0 | 0.044790 | 0.064825 | 00:00 | . 1 | 0.042065 | 0.059010 | 00:00 | . 2 | 0.039907 | 0.055658 | 00:00 | . 3 | 0.038412 | 0.053847 | 00:00 | . 4 | 0.037186 | 0.052595 | 00:00 | . 5 | 0.036020 | 0.052121 | 00:00 | . 6 | 0.035041 | 0.051959 | 00:00 | . 7 | 0.034370 | 0.051995 | 00:00 | . 8 | 0.033759 | 0.052022 | 00:00 | . 9 | 0.033237 | 0.052229 | 00:00 | . 4&#45800;&#44228; . - 하나의 배치 전체를 예측 . yhat=lrnr.model(X.to(&quot;cuda:0&quot;)) yhat . tensor([4.0162, 0.9041, 4.0706, 0.9730, 0.9861, 1.1032, 4.0559, 4.0745, 3.9329, 4.0195, 3.9139, 4.0732, 3.8666, 3.9556, 0.9634, 1.0055, 0.9944, 3.9826, 4.0456, 0.9961, 0.9438, 0.9291, 4.0212, 1.0700, 4.0543, 4.0441, 4.0918, 0.9850, 1.0140, 4.1212, 4.0628, 3.9923, 4.0395, 0.9331, 3.9581, 3.9999, 1.1152, 3.9131, 4.0565, 3.9264, 3.9619, 0.9421, 1.1348, 4.0688, 0.8939, 0.9684, 1.0505, 1.1034, 1.1027, 3.9411, 1.0582, 3.9680, 4.0465, 3.9554, 4.0419, 1.0965, 1.0784, 0.9954, 4.0205, 0.9373, 3.9045, 1.0255, 3.8102, 1.0640], device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;) . lrnr.model()은 GPU메모리에 존재하고 X는 일반메모리에 존재하므로 X를 GPU메모리로 옮겨주어야 함 | X.to(&quot;cuda:0&quot;)을 통하여 X를 GPU메모리로 옮기는 작업을 수행할 수 있다. | . - 하나의 유저가 하나의 아이템을 선택했다고 가정하고 예측 (주어진 자료중에서 예측) . X.shape . torch.Size([64, 2]) . X[0:1] . tensor([[18, 5]]) . 18번 유저가 5번 아이템(커피)를 먹는다면? | . lrnr.model(X[0:1].to(&quot;cuda:0&quot;)) . tensor([4.1128], device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;) . 평점은 4.1128정도 될것 | . - 하나의 유저가 하나의 아이템을 선택했다고 가정하고 예측 (주어지지 않은 자료중에서 예측) . X[0:1] . tensor([[18, 5]]) . Xnew = torch.tensor([[1, 2]]) . lrnr.model(Xnew.to(&quot;cuda:0&quot;)) . tensor([3.9397], device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;) . &#53581;&#49828;&#53944;&#48516;&#49437; . 1&#45800;&#44228; . df = pd.DataFrame({&#39;text&#39;:[&#39;h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??&#39;]*20000}) df . text . 0 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 1 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 2 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 3 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 4 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . ... ... | . 19995 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 19996 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 19997 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 19998 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 19999 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 20000 rows × 1 columns . dls = TextDataLoaders.from_df(df,text_col=&#39;text&#39;,is_lm=True) . dls.show_batch() . text text_ . 0 xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o | h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . | . 1 ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l | xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o | . 2 ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l | ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l | . 3 o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e | ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l | . 4 l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h | o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e | . 5 l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos | l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h | . 6 e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? | l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos | . 7 h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? | e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? | . 8 ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o | h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? | . is_lm: text의 생성에 관심이 있다면 True로 설정할 것 | . 2&#45800;&#44228; . lrnr = language_model_learner(dls, AWD_LSTM) . 3&#45800;&#44228; . lrnr.fit(1) . epoch train_loss valid_loss time . 0 | 0.575245 | 0.245803 | 00:11 | . 4&#45800;&#44228; . lrnr.predict(&#39;h e&#39;,n_words=30) . &#39;h e l l l o . h e l l . e l l o ? ? h e l l o ! ! h e l l o !&#39; . GAN (Generative Adversarial Network) . - 저자: 이안굿펠로우 (이름이 특이함. 좋은친구..) . 천재임 | 지도교수가 요수아 벤지오 | . - 논문 NIPS, 저는 이 논문 읽고 소름돋았어요.. . https://arxiv.org/abs/1406.2661 (현재시점, 38751회 인용되었음 $ to$ 48978회 인용..) | . - 최근 10년간 머신러닝 분야에서 가장 혁신적인 아이디어이다. (얀르쿤, 2014년 시점..) . - 무슨내용? 생성모형 . &#49373;&#49457;&#47784;&#54805;&#51060;&#46976;? (&#49772;&#50868; &#49444;&#47749;) . 만들수 없다면 이해하지 못한 것이다, 리처드 파인만 (천재 물리학자) . - 사진속에 들어있는 동물이 개인지 고양이인지 맞출수 있는 기계와 개와 고양이를 그릴수 있는 기계중 어떤것이 더 시각적보에 대한 이해가 깊다고 볼수 있는가? . - 진정으로 인공지능이 이미지를 이해했다면, 이미지를 만들수도 있어야 한다. $ to$ 이미지를 생성하는 모형을 만들어보자 $ to$ 성공 . . GAN&#51032; &#51025;&#50857;&#48516;&#50556; . - 내가 찍은 사진이 피카소의 화풍으로 표현된다면? . https://www.lgsl.kr/sto/stories/60/ALMA2020070001 | . - 퀸의 라이브에이드가 4k로 나온다면? . - 1920년대 서울의 모습이 칼라로 복원된다면? . - 딥페이크: 유명인의 가짜 포르노, 가짜뉴스, 협박(거짓기소) . - 게임영상 (파이널판타지) . - 거북이의 커버.. . - 너무 많아요..... . &#49373;&#49457;&#47784;&#54805;&#51060;&#46976;? &#53685;&#44228;&#54617;&#44284; &#48260;&#51204;&#51032; &#49444;&#47749; . 제한된 정보만으로 어떤 문제를 풀 때, 그 과정에서 원래의 문제보다 일반적인 문제를 풀지 말고, 가능한 원래의 문제를 직접 풀어야한다. 배프닉 (SVM 창시자) . - 이미지 $ boldsymbol{x}$가 주어졌을 경우 라벨을 $y$라고 하자. . - 이미지를 보고 라벨을 맞추는 일은 $p(y| boldsymbol{x})$에 관심이 있다. . - 이미지를 생성하는 일은 $p( boldsymbol{x},y)$에 관심이 있는것이다. . - 데이터의 생성확률 $p( boldsymbol{x},y)$을 알면 클래스의 사후확률 $p(y| boldsymbol{x})$를 알 수 있음. (아래의 수식 참고) 하지만 역은 불가능 . $$p(y|x) = frac{p(x,y)}{p(x)} = frac{p(x,y)}{ sum_{y}p(x,y)} $$ . 즉 이미지를 생성하는일은 분류문제보다 더 어려운 일이라 해석가능 | . - 따라서 배프닉의 원리에 의하면 식별적 분류가 생성적 분류보다 바람직한 접근법이라 할 수 있음. . - 하지만 다양한 현실문제에서 생성모형이 유용할때가 많다. . GAN&#51032; &#50896;&#47532; . - GAN은 생성모형중 하나임 . - GAN의 원리는 경찰과 위조지폐범이 서로 선의의(?) 경쟁을 통하여 서로 발전하는 모형으로 설명할 수 있다. . The generative model can be thought of as analogous to a team of counterfeiters, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles. . - 서로 적대적인(adversarial) 네트워크(network)를 동시에 학습시켜 가짜이미지를 만든다(generate) . - 무식한 상황극.. . 위조범:가짜돈을 만들어서 부자가 되어야지! (가짜돈을 그림) &gt; 경찰:(위조범이 만든 돈을 보고) 이건 가짜다! &gt; 위조범:걸렸군.. 더 정교하게 만들어야지.. &gt; 경찰:이건 진짠가?... --&gt; 상사에게 혼남. 그것도 구분못하냐고 &gt; 위조범:더 정교하게 만들자.. &gt; 경찰:더 판별능력을 업그레이드 하자! 반복.. . - 굉장히 우수한 경찰조차도 진짜와 가짜를 구분하지 못할때(=진짜 이미지를 0.5의 확률로만 진짜라고 말할때 = 가짜 이미지를 0.5의 확률로만 가짜라고 말할때) 학습을 멈춘다. . 1&#45800;&#44228; . path = untar_data(URLs.MNIST_SAMPLE) . dblock = DataBlock(blocks=(TransformBlock,ImageBlock), get_x = generate_noise, get_items=get_image_files, item_tfms=Resize(32)) dls = dblock.dataloaders(path) . dls.show_batch() . 2&#45800;&#44228; . counterfeiter = basic_generator(32,n_channels=3,n_extra_layers=1) police = basic_critic(32,n_channels=3,n_extra_layers=1) . lrnr = GANLearner.wgan(dls,counterfeiter,police) . 3&#45800;&#44228; . - lrnr.fit(10) 진행 . lrnr.fit(10) . /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/callback/core.py:69: UserWarning: You are shadowing an attribute (generator) that exists in the learner. Use `self.learn.generator` to avoid this warn(f&#34;You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this&#34;) /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/callback/core.py:69: UserWarning: You are shadowing an attribute (critic) that exists in the learner. Use `self.learn.critic` to avoid this warn(f&#34;You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this&#34;) /home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/callback/core.py:69: UserWarning: You are shadowing an attribute (gen_mode) that exists in the learner. Use `self.learn.gen_mode` to avoid this warn(f&#34;You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this&#34;) . epoch train_loss valid_loss gen_loss crit_loss time . 0 | -0.534740 | 0.451562 | 0.451562 | -0.741169 | 00:03 | . 1 | -0.575058 | 0.380455 | 0.380455 | -0.760576 | 00:03 | . 2 | -0.574557 | 0.341934 | 0.341934 | -0.752832 | 00:03 | . 3 | -0.579906 | 0.327053 | 0.327053 | -0.765308 | 00:03 | . 4 | -0.575423 | 0.395715 | 0.395715 | -0.752965 | 00:03 | . 5 | -0.573137 | 0.289887 | 0.289887 | -0.760712 | 00:03 | . 6 | -0.568658 | 0.352976 | 0.352976 | -0.747846 | 00:03 | . 7 | -0.554208 | 0.340820 | 0.340820 | -0.724155 | 00:03 | . 8 | -0.537785 | 0.241240 | 0.241240 | -0.705587 | 00:03 | . 9 | -0.527803 | 0.255229 | 0.255229 | -0.699837 | 00:03 | . lrnr.show_results() . - lrnr.fit(10) 추가로 진행 // 총20회 . lrnr.fit(10) . epoch train_loss valid_loss gen_loss crit_loss time . 0 | -0.530835 | 0.321795 | 0.321795 | -0.732250 | 00:03 | . 1 | -0.558991 | 0.302870 | 0.302870 | -0.726843 | 00:03 | . 2 | -0.434349 | 0.273795 | 0.273795 | -0.652403 | 00:03 | . 3 | -0.482198 | 0.266838 | 0.266838 | -0.693673 | 00:03 | . 4 | -0.516987 | 0.124863 | 0.124863 | -0.691952 | 00:03 | . 5 | -0.474437 | 0.231280 | 0.231280 | -0.693756 | 00:03 | . 6 | -0.537820 | 0.242874 | 0.242874 | -0.722241 | 00:03 | . 7 | -0.481492 | 0.263266 | 0.263266 | -0.611555 | 00:03 | . 8 | -0.524081 | 0.238987 | 0.238987 | -0.716421 | 00:03 | . 9 | -0.477778 | 0.256903 | 0.256903 | -0.627914 | 00:03 | . lrnr.show_results() . - lrnr.fit(10) 추가로 진행 // 총30회 . lrnr.fit(10) . epoch train_loss valid_loss gen_loss crit_loss time . 0 | -0.435657 | 0.215282 | 0.215282 | -0.612291 | 00:03 | . 1 | -0.473025 | 0.181170 | 0.181170 | -0.291532 | 00:03 | . 2 | -0.442681 | 0.223113 | 0.223113 | -0.452207 | 00:03 | . 3 | -0.439288 | 0.271226 | 0.271226 | -0.638193 | 00:03 | . 4 | -0.299585 | 0.257506 | 0.257506 | -0.530219 | 00:03 | . 5 | -0.353306 | 0.369160 | 0.369160 | -0.542340 | 00:03 | . 6 | -0.239010 | 0.069810 | 0.069810 | -0.292741 | 00:03 | . 7 | -0.315431 | 0.365071 | 0.365071 | -0.528452 | 00:03 | . 8 | -0.284204 | 0.207484 | 0.207484 | -0.397802 | 00:03 | . 9 | -0.311350 | 0.245315 | 0.245315 | -0.423371 | 00:03 | . lrnr.show_results() . 4&#45800;&#44228; (&#50630;&#51020;) .",
            "url": "https://guebin.github.io/STML2022/2022/09/14/(2%EC%A3%BC%EC%B0%A8)-9%EC%9B%9414%EC%9D%BC.html",
            "relUrl": "/2022/09/14/(2%EC%A3%BC%EC%B0%A8)-9%EC%9B%9414%EC%9D%BC.html",
            "date": " • Sep 14, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "(1주차) 9월6일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . Import . from fastai.vision.all import * . &#45936;&#51060;&#53552;&#51200;&#51109; . path = untar_data(URLs.PETS)/&#39;images&#39; # URLs.PETS: 스트링 -&gt; 주소가 저장되어 있음.. -&gt; 주소로 들어가보니 어떠한 압축파일이 자동으로 다운 받아짐, 이게 데이터 # untar_data: (1) URLs.PETS에 저장된 주소로 찾아가서 (2) 압축을 풀어서 (3) 어떠한 폴더에 저장, 그 폴더의 위치는 path 에 저장 . . 100.00% [811712512/811706944 00:10&lt;00:00] path # 여기에 그림이 있다는 말이지?? . Path(&#39;/root/.fastai/data/oxford-iiit-pet/images&#39;) . # 탐색... 여러파일들이 있기는함.. # Abyssinian_1.jpg 를 보고싶다면? PILImage.create(&#39;/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;) . # Abyssinian_100.jpg 를 보고싶다면? PILImage.create(&#39;/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_100.jpg&#39;) . - 그림을 확인 할 수 있는건 좋은데 이렇게 확인하니까 조금 귀찮음.. . _lst = [&#39;/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;,&#39;/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_10.jpg&#39;] . _lst[0] . &#39;/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39; . PILImage.create(_lst[0]) . files= get_image_files(path) files . (#7390) [Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/scottish_terrier_92.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/leonberger_173.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/shiba_inu_120.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Persian_26.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/yorkshire_terrier_86.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Ragdoll_56.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/german_shorthaired_2.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/japanese_chin_169.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_192.jpg&#39;)...] . files[0] . Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/scottish_terrier_92.jpg&#39;) . PILImage.create(files[0]) . print(files[2]) PILImage.create(files[2]) . /root/.fastai/data/oxford-iiit-pet/images/shiba_inu_120.jpg . print(files[3]) PILImage.create(files[3]) . /root/.fastai/data/oxford-iiit-pet/images/Persian_26.jpg . print(files[4]) PILImage.create(files[4]) . /root/.fastai/data/oxford-iiit-pet/images/yorkshire_terrier_86.jpg . print(files[5]) PILImage.create(files[5]) . /root/.fastai/data/oxford-iiit-pet/images/Ragdoll_56.jpg . print(files[6]) PILImage.create(files[6]) . /root/.fastai/data/oxford-iiit-pet/images/german_shorthaired_2.jpg . print(files[7]) PILImage.create(files[7]) . /root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg . print(files[8]) PILImage.create(files[8]) . /root/.fastai/data/oxford-iiit-pet/images/japanese_chin_169.jpg . # 특1: 대문자이면 고양이, 소문자이면 강아지그림이다!! (천재적인 저장방식) # 특2: 이미지크기가 서로 다르다.. . def label_func(fname): if fname[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . dls = ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(224)) # path 경로에서 # files 에 해당하는 파일들을 불러와서 X를 만들고 # item_tfms 에 정의된 방식으로 X를 변환하여 저장한다. 그리고 # label_func: &quot;파일이름&quot; -&gt; &quot;라벨&quot;, 에 저장된 함수내용을 바탕으로 y를 만들어 저장한다. # 이 모든것이 저장된 자료는 변수 dls에 저장한다. . dls.show_batch(max_n=16) . &#54617;&#49845; . # 우리의 1차 목표: 이미지 -&gt; 개/고양이 판단하는 모형을 채용하고, 그 모형에 데이터를 넣어서 학습하고, 그 모형의 결과를 판단하고 싶다. (즉 클래시파이어를 만든다는 소리) # 우리의 2차 목표: 그 모형에 &quot;새로운&quot; 자료를 전달하여 이미지를 분류할 것이다. (즉 클래시파이어를 쓴다는 소리) # cnn_learner 라는 함수를 이용해서 1차목표와 2차목표를 달성할 &quot;썸띵(Object)&quot;을 만들것임. ## 오브젝트란? 정보와 함수를 동시에 가지는 어떠한 집합체 # - 오브젝트.명사이름: 이것 통채로 하나의 변수처럼 쓸 수 있음. # - 오브젝트.동사이름: 이것 통채로 하나의 함수처럼 쓸 수 있음. (이때 함수의 첫번째 입력은 명시하지 않아도 오브젝트 그 자체가 된다) ## clafr에 필요한 명사(=정보) &lt;-- 우리가 넣어줘야하는 것들이 대부분 # (1) 모델정보: 클래시파이어로 누구를 뽑을것인가 (유명한 모델이 무엇인가? 잘 맞추는 모델이 무엇인가) # (2) 데이터: 데이터를 줘야함 # (3) 평가기준표: 채점을 할 지표 ## clafr에 필요한 동사(=함수) &lt;-- 이미 구현이 되어있음.. # (1) 학습 # (2) 결과를 판단 # (3) 예측 clsfr = cnn_learner(dls,resnet34,metrics=error_rate) # clsfr 라는 오브젝트를 만들건데.. # 그 오브젝트의 재료로 dls (데이터), resnet34 (데이터를 분석할 모형이름), metrics (모형의 성능을 평가할 기준) 를 넣음. . /usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code warn(&#34;`cnn_learner` has been renamed to `vision_learner` -- please update your code&#34;) /usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter &#39;pretrained&#39; is deprecated since 0.13 and will be removed in 0.15, please use &#39;weights&#39; instead. f&#34;The parameter &#39;{pretrained_param}&#39; is deprecated since 0.13 and will be removed in 0.15, &#34; /usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for &#39;weights&#39; are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights. warnings.warn(msg) Downloading: &#34;https://download.pytorch.org/models/resnet34-b627a593.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth . clsfr.fine_tune(1) # 학습을 하는 함수 . epoch train_loss valid_loss error_rate time . 0 | 0.189062 | 0.012517 | 0.006089 | 01:01 | . epoch train_loss valid_loss error_rate time . 0 | 0.051309 | 0.010439 | 0.003383 | 00:57 | . &#44592;&#51316; &#45936;&#51060;&#53552;&#47484; &#51096; &#47582;&#52628;&#45716;&#51648; &#54869;&#51064; . files[0] # 강아지 . Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/scottish_terrier_92.jpg&#39;) . clsfr.predict(files[0]) . (&#39;dog&#39;, TensorBase(1), TensorBase([6.8846e-07, 1.0000e+00])) . files[7] # 고양이 . Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg&#39;) . clsfr.predict(files[7]) . (&#39;cat&#39;, TensorBase(0), TensorBase([1.0000e+00, 1.3773e-08])) . clsfr.show_results() . &#50724;&#45813;&#48516;&#49437; . interpreter = Interpretation.from_learner(clsfr) # 오답을 분석하는 오브젝트를 만듬.. 재료는 클래시파이어! . interpreter.plot_top_losses(16) # 오답을 분석하는 오브젝트는 가장 오류가 높은 이미지를 정렬하여 보여주는 기능이 있음.. . &#51652;&#51676; &#51096;&#46104;&#45716;&#44172; &#47582;&#45716;&#44148;&#44032;? . clsfr.predict(files[7]) . (&#39;cat&#39;, TensorBase(0), TensorBase([1.0000e+00, 1.3773e-08])) . clsfr.predict(&#39;/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg&#39;) . (&#39;cat&#39;, TensorBase(0), TensorBase([1.0000e+00, 1.3773e-08])) . clsfr.predict(PILImage.create(&#39;/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg&#39;)) . (&#39;cat&#39;, TensorBase(0), TensorBase([1.0000e+00, 1.3773e-08])) . PILImage.create(&#39;2022-09-06-cat1.png&#39;) . clsfr.predict(PILImage.create(&#39;2022-09-06-cat1.png&#39;)) . (&#39;cat&#39;, TensorBase(0), TensorBase([1.0000e+00, 1.5662e-10])) . PILImage.create(&#39;2022-09-06-cat2.jpeg&#39;) . clsfr.predict(PILImage.create(&#39;2022-09-06-cat2.jpeg&#39;)) . (&#39;cat&#39;, TensorBase(0), TensorBase([0.9809, 0.0191])) . clsfr.predict(PILImage.create(&#39;2022-09-06-hani01.jpeg&#39;)) . (&#39;dog&#39;, TensorBase(1), TensorBase([3.2573e-10, 1.0000e+00])) . clsfr.predict(PILImage.create(&#39;2022-09-06-hani02.jpeg&#39;)) . (&#39;dog&#39;, TensorBase(1), TensorBase([7.0723e-07, 1.0000e+00])) . clsfr.predict(PILImage.create(&#39;2022-09-06-hani03.jpg&#39;)) . (&#39;dog&#39;, TensorBase(1), TensorBase([0.1814, 0.8186])) . &#49689;&#51228; . - 인터넷에 존재하는 개 혹은 고양이 이미지를 임의로 하나 불러온뒤 clsfr에 넣어보고 결과를 관찰하라. 관찰결과를 스크린샷하여 제출하라. . 숙제를 위한 예시코드 # https://dimg.donga.com/ugc/CDB/SHINDONGA/Article/5e/0d/9f/01/5e0d9f011a9ad2738de6.jpg &lt;-- 인터넷의 이미지 주소 img=PILImage.create(requests.get(&#39;https://dimg.donga.com/ugc/CDB/SHINDONGA/Article/5e/0d/9f/01/5e0d9f011a9ad2738de6.jpg&#39;).content) clsfr.predict(img) . | . - 숙제 못하겠으면 카톡으로 물어보세요! 답 알려드립니다. . - 숙제는 간단하게 편한 형식으로 제출하세요. (저는 스크린샷 선호해요..) pdf나 hwp로 만드실 필요 없습니다. .",
            "url": "https://guebin.github.io/STML2022/2022/09/07/(1%EC%A3%BC%EC%B0%A8)-9%EC%9B%946%EC%9D%BC.html",
            "relUrl": "/2022/09/07/(1%EC%A3%BC%EC%B0%A8)-9%EC%9B%946%EC%9D%BC.html",
            "date": " • Sep 7, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "(A1) 깃허브와 fastpages를 이용하여 블로그 개설하기",
            "content": "About this doc . - 본 포스트는 2021년 1학기 Python 입문 강의내용중 일부를 업로드 하였음. . - Github, fastpages를 사용하여 블로그를 개설하고 관리하는 방법에 대한 설명임. . .",
            "url": "https://guebin.github.io/STML2022/2021/08/17/(A1)-%EA%B9%83%ED%97%88%EB%B8%8C%EC%99%80-fastpages%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EA%B0%9C%EC%84%A4%ED%95%98%EA%B8%B0.html",
            "relUrl": "/2021/08/17/(A1)-%EA%B9%83%ED%97%88%EB%B8%8C%EC%99%80-fastpages%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EA%B0%9C%EC%84%A4%ED%95%98%EA%B8%B0.html",
            "date": " • Aug 17, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "최규빈 . guebin@jbnu.ac.kr | 자연과학대학교 본관 205호 | 카카오톡 오픈채널1 | . 2022년 2학기 종료 후 폐쇄 예정 &#8617; . |",
          "url": "https://guebin.github.io/STML2022/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://guebin.github.io/STML2022/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}